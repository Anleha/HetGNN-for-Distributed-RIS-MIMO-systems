{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0b7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, ELU, Sigmoid, BatchNorm1d as BN, ReLU6 as ReLU6\n",
    "import scipy.io\n",
    "from dgl.nn import HeteroGraphConv\n",
    "from dgl.utils import expand_as_pair\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Sigmoid, BatchNorm1d as BN\n",
    "import math\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74fd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#Channel generation\n",
    "#Channel generation\n",
    "def generate_location(num_users):\n",
    "    location_user = np.zeros((num_users,3))\n",
    "    # location_user = np.array([[20,30,0],[20,-30,0]])\n",
    "    # location_user = np.array([[10,30,0],[30,30,0],[10,-30,0],[30,-30,0]])\n",
    "    \n",
    "    for k in range(num_users):\n",
    "        # x = np.random.uniform(5, 35)\n",
    "        # y = np.random.uniform(-35, 35)\n",
    "        x = np.random.uniform(20,30)\n",
    "        # x = 25\n",
    "        if k <= int(num_users/2)-1:\n",
    "            y = np.random.uniform(20,45)\n",
    "            # y = 25\n",
    "        else:\n",
    "            y = np.random.uniform(-45,-20)\n",
    "            # y = -25\n",
    "        z = 0\n",
    "        coordinate_k = np.array([x, y, z])\n",
    "        location_user[k, :] = coordinate_k\n",
    "    return location_user\n",
    "\n",
    "def generate_RISlocation(RIS_index,num_RIS):\n",
    "    # location_RIS = np.empty([3])\n",
    "    x = (RIS_index+1)*10\n",
    "    y = 0\n",
    "    z = 20\n",
    "    coordinate = np.array([x, y, z])\n",
    "    \n",
    "    return coordinate\n",
    "def path_loss_r(d):\n",
    "    loss = 30 + 22.0 * np.log10(d)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def path_loss_d(d):\n",
    "    loss = 32.6 + 36.7 * np.log10(d)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def generate_pathloss_aoa_aod(location_user, location_bs, location_irs):\n",
    "    \"\"\"\n",
    "    :param location_user: array (num_user,2)\n",
    "    :param location_bs: array (2,)\n",
    "    :param location_irs: array (2,)\n",
    "    :return: pathloss = (pathloss_irs_bs, pathloss_irs_user, pathloss_bs_user)\n",
    "            cos_phi = (cos_phi_1, cos_phi_2, cos_phi_3)\n",
    "    \"\"\"\n",
    "    num_user = location_user.shape[0]\n",
    "    # ========bs-irs==============\n",
    "    d0 = np.linalg.norm(location_bs - location_irs)\n",
    "    pathloss_irs_bs = path_loss_r(d0)\n",
    "    aoa_bs = ( location_irs[0] - location_bs[0]) / d0\n",
    "    aod_irs_y = (location_bs[1]-location_irs[1]) / d0\n",
    "    aod_irs_z = (location_bs[2]-location_irs[2]) / d0\n",
    "    # =========irs-user=============\n",
    "    pathloss_irs_user = []\n",
    "    aoa_irs_y = []\n",
    "    aoa_irs_z = []\n",
    "    for k in range(num_user):\n",
    "        d_k = np.linalg.norm(location_user[k] - location_irs)\n",
    "        pathloss_irs_user.append(path_loss_r(d_k))\n",
    "        aoa_irs_y_k = (location_user[k][1] - location_irs[1]) / d_k\n",
    "        aoa_irs_z_k = (location_user[k][2] - location_irs[2]) / d_k\n",
    "        aoa_irs_y.append(aoa_irs_y_k)\n",
    "        aoa_irs_z.append(aoa_irs_z_k)\n",
    "    aoa_irs_y = np.array(aoa_irs_y)\n",
    "    aoa_irs_z = np.array(aoa_irs_z)\n",
    "\n",
    "    # =========bs-user=============\n",
    "    pathloss_bs_user = np.zeros([num_user, 1])\n",
    "    for k in range(num_user):\n",
    "        d_k = np.linalg.norm(location_user[k] - location_bs)\n",
    "        pathloss_bs_user_k = path_loss_d(d_k)\n",
    "        pathloss_bs_user[k, :] = pathloss_bs_user_k\n",
    "\n",
    "    pathloss = (pathloss_irs_bs, np.array(pathloss_irs_user), np.array(pathloss_bs_user))\n",
    "    aoa_aod = (aoa_bs, aod_irs_y, aod_irs_z, aoa_irs_y, aoa_irs_z)\n",
    "    return pathloss, aoa_aod\n",
    "\n",
    "def generate_channel(params_system, location_bs=np.array([0, 0, 0]), location_irs=np.array([0, 0, 0]),\n",
    "                      location_user_initial=None, Rician_factor=10, scale_factor=100, num_samples=100,irs_Nh=10, num_RIS=1):\n",
    "    # scale_factor: can be viewed as (downlink noise_power_dB- downlink Pt)\n",
    "\n",
    "    (num_antenna_bs, num_elements_irs, num_user) = params_system \n",
    "        # location_irs2 = np.array([100, 0, 0])\n",
    "        #channel BS to user\n",
    "    \n",
    "    for RIS_idx in range(num_RIS):\n",
    "        location_irs = generate_RISlocation(RIS_idx,num_RIS)\n",
    "        channel_bs_irs1, channel_bs_user_tmp, channel_irs_user1, set_location_user = [], [], [], []\n",
    "        for ii in range(num_samples):\n",
    "            if location_user_initial is None:\n",
    "                location_user = generate_location(num_user)\n",
    "                set_location_user.append(location_user)\n",
    "            else:\n",
    "                location_user = location_user_initial\n",
    "                set_location_user.append(location_user)\n",
    "        \n",
    "            pathloss, aoa_aod = generate_pathloss_aoa_aod(location_user, location_bs, location_irs)\n",
    "            (pathloss_irs_bs, pathloss_irs_user, pathloss_bs_user) = pathloss\n",
    "            (aoa_bs, aod_irs_y, aod_irs_z, aoa_irs_y, aoa_irs_z) = aoa_aod\n",
    "            \n",
    "            pathloss_bs_user = pathloss_bs_user - scale_factor\n",
    "            pathloss_irs_bs = pathloss_irs_bs - scale_factor / 2\n",
    "            pathloss_irs_user = pathloss_irs_user - scale_factor / 2\n",
    "            pathloss_bs_user = np.sqrt(10 ** ((-pathloss_bs_user) / 10))\n",
    "            pathloss_irs_user = np.sqrt(10 ** ((-pathloss_irs_user) / 10))\n",
    "            pathloss_irs_bs = np.sqrt(10 ** ((-pathloss_irs_bs) / 10))\n",
    "            \n",
    "            # tmp:(num_antenna_bs,num_user) channel between BS and user\n",
    "            if RIS_idx == 0:\n",
    "                tmp = np.random.normal(loc=0, scale=np.sqrt(0.5), size=[num_antenna_bs, num_user]) \\\n",
    "                      + 1j * np.random.normal(loc=0, scale=np.sqrt(0.5), size=[num_antenna_bs, num_user])\n",
    "                tmp = tmp * pathloss_bs_user.reshape(1, num_user)\n",
    "                channel_bs_user_tmp.append(tmp)\n",
    "                \n",
    "            # tmp: (num_antenna_bs,num_elements_irs) channel between IRS and BS\n",
    "            tmp = np.random.normal(loc=0, scale=np.sqrt(0.5), size=[num_antenna_bs, num_elements_irs]) \\\n",
    "                  + 1j * np.random.normal(loc=0, scale=np.sqrt(0.5), size=[num_antenna_bs, num_elements_irs])\n",
    "            a_bs = np.exp(1j * np.pi * aoa_bs * np.arange(num_antenna_bs))\n",
    "            a_bs = np.reshape(a_bs, [num_antenna_bs, 1])\n",
    "    \n",
    "            i1 = np.mod(np.arange(num_elements_irs),irs_Nh)\n",
    "            i2 = np.floor(np.arange(num_elements_irs)/irs_Nh)\n",
    "            a_irs_bs = np.exp(1j * np.pi * (i1*aod_irs_y+i2*aod_irs_z))\n",
    "            a_irs_bs =  np.reshape(a_irs_bs, [num_elements_irs, 1])\n",
    "            los_irs_bs = a_bs @ np.transpose(a_irs_bs.conjugate())\n",
    "            tmp = np.sqrt(Rician_factor / (1 + Rician_factor)) * los_irs_bs + np.sqrt(1/(1 + Rician_factor)) * tmp\n",
    "            tmp = tmp * pathloss_irs_bs\n",
    "            channel_bs_irs1.append(tmp)\n",
    "            \n",
    "            # tmp:(num_elements_irs,num_user) channel between IRS and user\n",
    "            tmp = np.random.normal(loc=0, scale=np.sqrt(0.5), size=[num_elements_irs, num_user]) \\\n",
    "                  + 1j * np.random.normal(loc=0, scale=np.sqrt(0.5), size=[num_elements_irs, num_user])\n",
    "            for k in range(num_user):\n",
    "                a_irs_user = np.exp(1j * np.pi * (i1 * aoa_irs_y[k] + i2 * aoa_irs_z[k]))\n",
    "                tmp[:, k] = np.sqrt(Rician_factor/(1+Rician_factor))*a_irs_user+np.sqrt(1/(1+Rician_factor))*tmp[:, k]\n",
    "                tmp[:, k] = tmp[:, k] * pathloss_irs_user[k]\n",
    "            channel_irs_user1.append(tmp)\n",
    "             \n",
    "        aa = 1\n",
    "        if RIS_idx == 0:\n",
    "            channel_bs_user = channel_bs_user_tmp\n",
    "            channel_irs_user = np.array(channel_irs_user1)\n",
    "            channel_bs_irs = np.array(channel_bs_irs1)\n",
    "        else:\n",
    "            channel_irs_user = np.concatenate((channel_irs_user,np.array(channel_irs_user1)),axis=1)\n",
    "            channel_bs_irs = np.concatenate((channel_bs_irs,np.array(channel_bs_irs1)),axis=2)\n",
    "        \n",
    "    # channel_irs_user = np.concatenate((np.array(channel_irs_user1),np.array(channel_irs_user2)),axis=1)\n",
    "    # channel_bs_irs = np.concatenate((np.array(channel_bs_irs1),np.array(channel_bs_irs2)),axis=2)\n",
    "    channels = (np.array(channel_bs_user), channel_irs_user, channel_bs_irs)\n",
    "    return channels, set_location_user\n",
    "\n",
    "\n",
    "\n",
    "def channel_complex2real(channels):\n",
    "    channel_bs_user, channel_irs_user, channel_bs_irs = channels\n",
    "    (num_sample, num_antenna_bs, num_elements_irs) = channel_bs_irs.shape\n",
    "    num_user = channel_irs_user.shape[2]\n",
    "\n",
    "    A_T_real = np.zeros([num_sample, 2 * num_elements_irs, 2 * num_antenna_bs, num_user])\n",
    "    # Hd_real = np.zeros([num_sample, 2 * num_antenna_bs, num_user])\n",
    "    set_channel_combine_irs = np.zeros([num_sample, num_antenna_bs, num_elements_irs, num_user], dtype=complex)\n",
    "\n",
    "    for kk in range(num_user):\n",
    "        channel_irs_user_k = channel_irs_user[:, :, kk]\n",
    "        channel_combine_irs = channel_bs_irs * channel_irs_user_k.reshape(num_sample, 1, num_elements_irs)\n",
    "        set_channel_combine_irs[:, :, :, kk] = channel_combine_irs\n",
    "        A_tmp_tran = np.transpose(channel_combine_irs, (0, 2, 1))\n",
    "        A_tmp_real1 = np.concatenate([A_tmp_tran.real, A_tmp_tran.imag], axis=2)\n",
    "        A_tmp_real2 = np.concatenate([-A_tmp_tran.imag, A_tmp_tran.real], axis=2)\n",
    "        A_tmp_real = np.concatenate([A_tmp_real1, A_tmp_real2], axis=1)\n",
    "        A_T_real[:, :, :, kk] = A_tmp_real\n",
    "\n",
    "    Hd_real = np.concatenate([channel_bs_user.real, channel_bs_user.imag], axis=1)\n",
    "\n",
    "    return A_T_real, Hd_real, np.array(set_channel_combine_irs)\n",
    "#%%\n",
    "class RIS_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Phasenet = nn.Sequential(\n",
    "                        nn.Conv2d(2*K,64,4,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64,64,4,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(21760,256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm1d(256),\n",
    "                        nn.Linear(256,3*M),\n",
    "                        nn.Sigmoid()\n",
    "                        )\n",
    "#         for m in self.Phasenet.modules():\n",
    "#             if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "#                 init.xavier_uniform_(m.weight)\n",
    "                \n",
    "        self.Beamnet = nn.Sequential(\n",
    "                        nn.Linear(2*Nt*K, 256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm1d(256),\n",
    "                        nn.Linear(256,256),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm1d(256),\n",
    "                        nn.Linear(256,2*Nt*K))\n",
    "#         for m in self.Beamnet.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self,x,H,G):\n",
    "        batch = H.shape[0]\n",
    "        phase = self.Phasenet(x)\n",
    "        phase_T = phase[:,:M]\n",
    "        phase_R = phase[:,M:2*M]\n",
    "        phase_T = torch.reshape(phase_T,(batch,-1))\n",
    "        phase_R = torch.reshape(phase_R,(batch,-1))\n",
    "        \n",
    "        amplitude_T = phase[:,2*M:]\n",
    "        amplitude_T = torch.reshape(amplitude_T,(batch,-1))\n",
    "        amplitude_R = 1 - amplitude_T\n",
    "        \n",
    "        theta_T = torch.exp(1j*2*math.pi*phase_T)\n",
    "        theta_T = torch.sqrt(amplitude_T)*theta_T\n",
    "        \n",
    "        theta_R = torch.exp(1j*2*math.pi*phase_R)\n",
    "        theta_R = torch.sqrt(amplitude_R)*theta_R\n",
    "        \n",
    "        phi_T = torch.diag_embed(theta_T)\n",
    "        phi_R = torch.diag_embed(theta_R)\n",
    "        \n",
    "        temp_T = torch.matmul(H,phi_T)\n",
    "        temp_R = torch.matmul(H,phi_R)\n",
    "        \n",
    "        CSI_T = torch.matmul(temp_T,G[:,:,:int(K/2)])\n",
    "        CSI_R = torch.matmul(temp_R,G[:,:,int(K/2):])\n",
    "        CSI = torch.concat((CSI_T,CSI_R),dim=2)\n",
    "        CSI_real = torch.view_as_real(CSI)\n",
    "        CSI_real = torch.reshape(CSI_real,(batch,Nt*2*K))\n",
    "        \n",
    "        beam = self.Beamnet(CSI_real)\n",
    "        aa = 1\n",
    "        return phi_T, phi_R, beam\n",
    "#%%\n",
    "def sr_loss(beam,phi_T, phi_R,H,G):\n",
    "    #calculate sumrate of the system\n",
    "    #phase: predicted phase of RIS\n",
    "    #H,G: channel links\n",
    "    #beam: predicted beamforming matrix \n",
    "    \n",
    "    batch = H.shape[0]\n",
    "    Nt = H.shape[1]\n",
    "    # print(G.shape)\n",
    "    K = G.shape[2] #num of user\n",
    "    \n",
    "   \n",
    "    \n",
    "    temp = torch.reshape(beam,(batch,K,Nt,2))\n",
    "    BF_matrix = torch.view_as_complex(temp)\n",
    "    BF_matrix = torch.transpose(BF_matrix,1,2)\n",
    "    \n",
    "    \n",
    "    mean = (abs(BF_matrix)**2/2).mean()     \n",
    "    beam_complex = math.sqrt(Pmax)*BF_matrix/torch.sqrt(mean*Nt*K)\n",
    "\n",
    "    #transpose variables to the correct shape\n",
    "    \n",
    "    H = torch.transpose(H,1,2)\n",
    "    G = torch.transpose(G,1,2)\n",
    "    \n",
    "    sum_rate = 0\n",
    "    rate = torch.zeros(batch,K)\n",
    "    # T region user\n",
    "    for i in range(int(K/2)):\n",
    "        interference = 0\n",
    "        gk = G[:,i,:].unsqueeze(1) #channel from RIS to the k-th user\n",
    "        temp = torch.matmul(gk,phi_T)\n",
    "        temp = torch.matmul(temp,H)\n",
    "        \n",
    "        for j in range(K):\n",
    "            if i!=j:            \n",
    "                interference_temp = torch.matmul((temp),beam_complex[:,:,j].unsqueeze(2)).squeeze() #effective channel for the k-th user\n",
    "                interference += torch.square(torch.abs(interference_temp))\n",
    "                \n",
    "        received_snr = torch.matmul(temp,beam_complex[:,:,i].unsqueeze(2)).squeeze()\n",
    "        received_snr = torch.square(torch.abs(received_snr))\n",
    "        sum_rate += torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        rate[:,i] = torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        \n",
    "    #R region user\n",
    "    \n",
    "    for i in range(int(K/2),K):\n",
    "        interference = 0\n",
    "        gk = G[:,i,:].unsqueeze(1) #channel from RIS to the k-th user\n",
    "        temp = torch.matmul(gk,phi_R)\n",
    "        temp = torch.matmul(temp,H)\n",
    "        \n",
    "        for j in range(K):\n",
    "            if i!=j:            \n",
    "                interference_temp = torch.matmul((temp),beam_complex[:,:,j].unsqueeze(2)).squeeze() #effective channel for the k-th user\n",
    "                interference += torch.square(torch.abs(interference_temp))\n",
    "                \n",
    "        received_snr = torch.matmul(temp,beam_complex[:,:,i].unsqueeze(2)).squeeze()\n",
    "        received_snr = torch.square(torch.abs(received_snr))\n",
    "        sum_rate += torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        rate[:,i] = torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        \n",
    "    \n",
    "                \n",
    "    return torch.neg(torch.mean(sum_rate))\n",
    "#%%\n",
    "def train(model,device):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for  feature, H,G in (train_loader):\n",
    "        batch = H.shape[0]\n",
    "        feature = feature.to(device)\n",
    "        H = H.to(device)\n",
    "        G = G.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        phi_T, phi_R, beam = model(feature,H,G)\n",
    "        \n",
    "        loss = sr_loss(beam,phi_T, phi_R,H,G)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_all += loss.item() * batch\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "#%%\n",
    "def test(loader):\n",
    "    # model.eval()\n",
    "    loss_all = 0\n",
    "    for  feature, H,G in (loader):\n",
    "        batch = H.shape[0]\n",
    "        feature = feature.to(device)\n",
    "        H = H.to(device)\n",
    "        G = G.to(device)\n",
    "        \n",
    "        phi_T, phi_R, beam = model(feature,H,G)\n",
    "        \n",
    "        loss = sr_loss(beam,phi_T, phi_R,H,G)      \n",
    "        loss_all += loss.item() * batch\n",
    "#         optimizer.step()\n",
    "        \n",
    "    return loss_all / len(loader.dataset), beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a962fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build graph dataset\n",
    "class PCDataset(DGLDataset):\n",
    "    def __init__(self, H, G, Nt, N_RIS, num_RIS, K):\n",
    "        num_sample = H.shape[0]\n",
    "        # self.H = torch.reshape(torch.view_as_real(H),(num_sample,Nt,2*N_RIS))\n",
    "        # self.G = torch.reshape(torch.view_as_real(G),(num_sample,N_RIS,2*K))\n",
    "        \n",
    "        self.H = H \n",
    "        self.G = G\n",
    "        self.num_RIS = num_RIS\n",
    "        # self.D = D\n",
    "        # self.D_real = torch.view_as_real(D) \n",
    "        self.H_real = torch.view_as_real(H)\n",
    "        self.G_real = torch.view_as_real(G)\n",
    "        # self.cross = torch.tensor(cross, dtype = torch.float)\n",
    "        self.K = K\n",
    "        self.Nt = Nt\n",
    "        self.N_RIS = N_RIS\n",
    "        self.get_cg()\n",
    "        super().__init__(name='beamforming')\n",
    "        \n",
    "        \n",
    "    def build_graph(self, idx):\n",
    "\n",
    "        graph = dgl.heterograph({('RIS', 'RIS-UE', 'UE') : self.RIS_UE,('UE', 'UE-RIS', 'RIS') : self.UE_RIS})\n",
    "        \n",
    "        UE_node_ft = torch.ones((self.K,1))\n",
    "        RIS_node_ft = torch.ones((self.N_RIS*self.num_RIS,1))\n",
    "        \n",
    "        edge_ft_RIS_UE = torch.zeros((self.N_RIS*self.num_RIS*self.K,2*self.Nt))\n",
    "        count = 0\n",
    "        for k in range(K):\n",
    "            for i in range(self.N_RIS*self.num_RIS):\n",
    "                temp = torch.matmul(self.H[idx,:,i].unsqueeze(1),self.G[idx,i,k].unsqueeze(0).unsqueeze(1))\n",
    "                temp = torch.view_as_real(temp)\n",
    "                edge_ft_RIS_UE[count] = torch.reshape(temp,(2*Nt,-1)).squeeze()\n",
    "                count += 1\n",
    "        \n",
    "        edge_ft_UE_RIS = torch.zeros((self.N_RIS*self.num_RIS*self.K,2*self.Nt))\n",
    "        count = 0\n",
    "        for i in range(self.N_RIS*self.num_RIS):\n",
    "            for k in range(K):\n",
    "                temp = torch.matmul(self.H[idx,:,i].unsqueeze(1),self.G[idx,i,k].unsqueeze(0).unsqueeze(1))\n",
    "                temp = torch.view_as_real(temp)\n",
    "                edge_ft_UE_RIS[count] = torch.reshape(temp,(2*Nt,-1)).squeeze()\n",
    "                count += 1\n",
    "    \n",
    "            \n",
    "        graph.nodes['UE'].data['feat'] = UE_node_ft\n",
    "        graph.nodes['RIS'].data['feat'] = RIS_node_ft\n",
    "        \n",
    "        graph.edges['RIS-UE'].data['feat'] = edge_ft_RIS_UE\n",
    "        graph.edges['UE-RIS'].data['feat'] = edge_ft_UE_RIS\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def get_cg(self):\n",
    "        ## The graph is a fully connected bipartite graph\n",
    "        self.BS_RIS = []; self.RIS_BS = []\n",
    "        self.UE_RIS = []; self.RIS_UE = []\n",
    "        self.BS_UE = []; self.UE_BS = []\n",
    "        for i in range(0,self.K):\n",
    "            for j in range(0,self.num_RIS*self.N_RIS):\n",
    "                self.UE_RIS.append([i,j])\n",
    "                self.RIS_UE.append([j,i])\n",
    "        # for i in range(0,self.Nt):\n",
    "        #     for j in range(0,self.K):\n",
    "        #         self.BS_UE.append([i,j])\n",
    "        #         self.UE_BS.append([j,i])\n",
    "                    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.H.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        return self.graph_list[index], self.H[index], self.G[index]\n",
    "\n",
    "    def process(self):\n",
    "        n = self.H.shape[0]\n",
    "        self.graph_list = []\n",
    "        for i in range(n):\n",
    "            graph = self.build_graph(i)\n",
    "            self.graph_list.append(graph)\n",
    "#%%\n",
    "def collate(samples):\n",
    "    '''DGL collate function'''\n",
    "    graphs, H, G = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.stack(H), torch.stack(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b1a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Graph neural network model for RIS system\n",
    "\n",
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, node_dim, feature_dim, **kwargs):\n",
    "        super(EdgeConv, self).__init__()\n",
    "        self.lin = MLP([node_dim, node_dim])\n",
    "        self.res_lin = MLP([node_dim, feature_dim])\n",
    "        self.bn = BN(32)\n",
    "        #self.reset_parameters()\n",
    "\n",
    "    def concat_message_function(self, edges):\n",
    "        concat_message = torch.cat([edges.src['hid'], edges.dst['hid'], edges.data['feat']], axis = 1)\n",
    "        \n",
    "        return {'out': self.lin(concat_message)}\n",
    "    \n",
    "    def forward(self, g, inputs):\n",
    "        with g.local_scope():\n",
    "            feat_src, feat_dst = expand_as_pair(inputs, g)\n",
    "            g.srcdata['hid'] = feat_src\n",
    "            g.dstdata['hid'] = feat_dst\n",
    "            \n",
    "            g.apply_edges(self.concat_message_function)\n",
    "            # g.edata['out'] = self.lin(g.edata['out'])\n",
    "            g.update_all(fn.copy_e('out', 'm'),\n",
    "                         fn.mean('m', 'hid'))\n",
    "            # return g.dstdata['hid'] + self.res_lin(feat_dst)\n",
    "            return self.res_lin(g.dstdata['hid'])\n",
    "    \n",
    "#%%\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_dim = 256\n",
    "        \n",
    "        self.conv1 = HeteroGraphConv({rel:EdgeConv(34,self.feature_dim)\n",
    "                                            for rel in ['BS-RIS', 'RIS-BS', 'RIS-UE', 'UE-RIS']}, aggregate='sum')\n",
    "        self.conv2= HeteroGraphConv({rel:EdgeConv(576,self.feature_dim)\n",
    "                                            for rel in ['BS-RIS', 'RIS-BS', 'RIS-UE', 'UE-RIS']}, aggregate='sum')\n",
    "        self.conv3 = HeteroGraphConv({rel:EdgeConv(576,self.feature_dim)\n",
    "                                            for rel in ['BS-RIS', 'RIS-BS', 'RIS-UE', 'UE-RIS']}, aggregate='sum')\n",
    "        # self.conv4 = HeteroGraphConv({rel:EdgeConv(576,self.feature_dim)\n",
    "        #                                     for rel in ['BS-RIS', 'RIS-BS', 'RIS-UE', 'UE-RIS']}, aggregate='sum')\n",
    "        # self.mlp_BS = MLP([32, 64])\n",
    "        # self.mlp_BS = Seq(*[self.mlp_BS, Seq(Lin(64, 2*Nt), Sigmoid())])\n",
    "        \n",
    "        # self.mlp_RIS = MLP([32, 16])\n",
    "        # self.mlp_RIS = Seq(*[self.mlp_RIS, Seq(Lin(16, 2), Sigmoid())])\n",
    "        \n",
    "        self.mlp_BS = nn.Sequential(\n",
    "                    nn.Linear(self.feature_dim, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(256),\n",
    "                    nn.Linear(256, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(256),\n",
    "                    nn.Linear(256, Nt*2)\n",
    "                    # nn.Tanh()\n",
    "                    )\n",
    "        self.mlp_RIS = nn.Sequential(\n",
    "                    nn.Linear(self.feature_dim, 64),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.BatchNorm1d(64),\n",
    "                    nn.Linear(64, 2),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "        self.mlp_power = nn.Sequential(\n",
    "                    nn.Linear(self.feature_dim, 64),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.BatchNorm1d(64),\n",
    "                    nn.Linear(64, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "    def intermediate_predictions(self, node_features):\n",
    "        beam = self.mlp_BS(node_features['UE'])\n",
    "        phase = self.mlp_RIS(node_features['RIS'])\n",
    "        amplitude = self.mlp_power(node_features['RIS'])\n",
    "        return beam, phase, amplitude\n",
    "    \n",
    "    def forward(self, g, inputs):\n",
    "        out = self.conv1(g, inputs)\n",
    "        \n",
    "        beam, phase, amplitude = self.intermediate_predictions(out)\n",
    "        out['UE'] = torch.cat([out['UE'], beam], dim=1)\n",
    "        # out['RIS'] = torch.cat([out['RIS'], phase, amplitude], dim=1)\n",
    "        \n",
    "        out = self.conv2(g, out)\n",
    "        beam, phase, amplitude = self.intermediate_predictions(out)\n",
    "        out['UE'] = torch.cat([out['UE'], beam], dim=1)\n",
    "        # out['RIS'] = torch.cat([out['RIS'], phase, amplitude], dim=1)\n",
    "        \n",
    "        out = self.conv3(g, out)\n",
    "        # beam, phase, amplitude = self.intermediate_predictions(out)\n",
    "        # out['UE'] = torch.cat([out['UE'], beam], dim=1)\n",
    "        \n",
    "        # out = self.conv4(g, out)\n",
    "        \n",
    "        beam = self.mlp_BS(out['UE'])\n",
    "        phase = self.mlp_RIS(out['RIS'])\n",
    "        amplitude = self.mlp_power(out['RIS'])\n",
    "        return beam, phase, amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e1a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function for beamforming task\n",
    "def sr_loss(beam,phase, amplitude,H,G,N_RIS,num_RIS):\n",
    "    #calculate sumrate of the system\n",
    "    #phase: predicted phase of RIS\n",
    "    #H,G: channel links\n",
    "    #beam: predicted beamforming matrix \n",
    "    \n",
    "    batch = H.shape[0]\n",
    "    Nt = H.shape[1]\n",
    "    # print(G.shape)\n",
    "    K = G.shape[2] #num of user\n",
    "    \n",
    "    # print(batch)\n",
    "    # print(Nt)\n",
    "    # print(K)\n",
    "    \n",
    "    amplitude_T = amplitude\n",
    "    \n",
    "    # phase_T = phase[:,:N_RIS]\n",
    "    # phase_R = phase[:,N_RIS:]\n",
    "    \n",
    "    phase_T = phase[:,0]\n",
    "    phase_R = phase[:,1]\n",
    "    \n",
    "    phase_T = torch.reshape(phase_T,(batch,-1))\n",
    "    phase_R = torch.reshape(phase_R,(batch,-1))\n",
    "    amplitude_T = torch.reshape(amplitude_T,(batch,-1))\n",
    "    amplitude_R = 1 - amplitude_T\n",
    "    # phase = torch.reshape(phase,(batch,-1))\n",
    "    # amplitude_T = phase[::,]\n",
    "    amplitude_T = torch.sqrt(amplitude_T)\n",
    "    amplitude_R = torch.sqrt(amplitude_R)\n",
    "    \n",
    "    temp = torch.reshape(beam,(batch,K,Nt,2))\n",
    "    BF_matrix = torch.view_as_complex(temp)\n",
    "    BF_matrix = torch.transpose(BF_matrix,1,2)\n",
    "    \n",
    "    # BF_matrix = torch.nn.functional.normalize(BF_matrix,dim=2) #power normalization\n",
    "    # beam_complex = BF_matrix*math.sqrt(Pmax/K)\n",
    "    \n",
    "    # beam_complex = BF_matrix*math.sqrt(Pmax/Nt)\n",
    "    \n",
    "    mean = (abs(BF_matrix)**2).mean()     \n",
    "    beam_complex = math.sqrt(Pmax)*BF_matrix/torch.sqrt(mean*Nt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #transpose variables to the correct shape\n",
    "    \n",
    "    H = torch.transpose(H,1,2)\n",
    "    G = torch.transpose(G,1,2)\n",
    "\n",
    "    theta_T = torch.exp(1j*2*math.pi*phase_T) #reflecting vector\n",
    "    # theta_T = torch.sqrt(amplitude_T)*theta_T\n",
    "     \n",
    "    theta_R = torch.exp(1j*2*math.pi*phase_R) #reflecting vector\n",
    "    # theta_R = amplitude_R*theta_R\n",
    "    \n",
    "    phi_T = torch.diag_embed(theta_T)\n",
    "    phi_R = torch.diag_embed(theta_R)\n",
    "    \n",
    "    g = torch.zeros(batch,Nt,K, dtype=torch.complex64,device=device)\n",
    "    \n",
    "    # sum_rate = rate_calculator(H, G, g, beam_complex, Nt, K, N_RIS, num_RIS, theta_T, theta_R, amplitude_T, amplitude_R, 1)\n",
    "    sum_rate = 0\n",
    "    rate = torch.zeros(batch,K)\n",
    "    # T region user\n",
    "    for i in range(int(K/2)):\n",
    "        interference = 0\n",
    "        gk = G[:,i,:].unsqueeze(1) #channel from RIS to the k-th user\n",
    "        temp = torch.matmul(gk,phi_T)\n",
    "        temp = torch.matmul(temp,H)\n",
    "        \n",
    "        for j in range(K):\n",
    "            if i!=j:            \n",
    "                interference_temp = torch.matmul((temp),beam_complex[:,:,j].unsqueeze(2)).squeeze() #effective channel for the k-th user\n",
    "                interference += torch.square(torch.abs(interference_temp))\n",
    "                \n",
    "        received_snr = torch.matmul(temp,beam_complex[:,:,i].unsqueeze(2)).squeeze()\n",
    "        received_snr = torch.square(torch.abs(received_snr))\n",
    "        sum_rate += torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        rate[:,i] = torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        \n",
    "    #R region user\n",
    "    \n",
    "    for i in range(int(K/2),K):\n",
    "        interference = 0\n",
    "        gk = G[:,i,:].unsqueeze(1) #channel from RIS to the k-th user\n",
    "        temp = torch.matmul(gk,phi_R)\n",
    "        temp = torch.matmul(temp,H)\n",
    "        \n",
    "        for j in range(K):\n",
    "            if i!=j:            \n",
    "                interference_temp = torch.matmul((temp),beam_complex[:,:,j].unsqueeze(2)).squeeze() #effective channel for the k-th user\n",
    "                interference += torch.square(torch.abs(interference_temp))\n",
    "                \n",
    "        received_snr = torch.matmul(temp,beam_complex[:,:,i].unsqueeze(2)).squeeze()\n",
    "        received_snr = torch.square(torch.abs(received_snr))\n",
    "        sum_rate += torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        rate[:,i] = torch.log2(1 + torch.div(received_snr,(interference+1))) \n",
    "        \n",
    "    \n",
    "                \n",
    "    return torch.neg(torch.mean(sum_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70171c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def train(model,device):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for batch_idx, (g, H, G) in enumerate(train_loader):\n",
    "        #data = data.to(device)\n",
    "        batch = H.shape[0]\n",
    "        g = g.to(device)\n",
    "        H = H.to(device)\n",
    "        \n",
    "        \n",
    "        G = G.to(device)\n",
    "        # D = D.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        user_feats = g.nodes['UE'].data['feat']\n",
    "        RIS_feats = g.nodes['RIS'].data['feat']\n",
    "        \n",
    "        node_features = {'UE': user_feats, 'RIS':RIS_feats}\n",
    "        beam, phase, amplitude = model(g, node_features)\n",
    "        \n",
    "        loss = sr_loss(beam, phase, amplitude, H, G, N_RIS, num_RIS)\n",
    "        loss.backward()\n",
    "\n",
    "        loss_all += loss.item() * batch\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "#%%\n",
    "def test(loader):\n",
    "    # model.eval()\n",
    "    correct = 0\n",
    "    for (g, H, G) in loader:\n",
    "        batch = H.shape[0]\n",
    "        g = g.to(device)\n",
    "        H = H.to(device)\n",
    "        G = G.to(device)\n",
    "       \n",
    "        user_feats = g.nodes['UE'].data['feat']\n",
    "        RIS_feats = g.nodes['RIS'].data['feat']\n",
    "        \n",
    "        node_features = {'UE': user_feats, 'RIS':RIS_feats}\n",
    "        beam, phase, amplitude = model(g, node_features)\n",
    "        # print(G.shape)\n",
    "        loss = sr_loss(beam, phase, amplitude, H, G, N_RIS, num_RIS)\n",
    "        correct += loss.item() * batch\n",
    "    return correct / len(loader.dataset), beam, phase, amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c424372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system parameter\n",
    "Nt = 16 #Number of BS antenna\n",
    "N_RIS = 4 #Number of RIS elements\n",
    "K = 8 #number of user\n",
    "num_RIS = 4 #Number of RISs\n",
    "train_sample = 1200\n",
    "Pmax = 1\n",
    "train_num = 1000\n",
    "#%%\n",
    "num_antenna_bs, N_RIS, K, num_sample = Nt, N_RIS, K, train_sample\n",
    "params_system = (num_antenna_bs, N_RIS, K)\n",
    "noise_power_db, Rician_factor = -100, 2\n",
    "location_user = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d319b3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_system' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#generate channel and create dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m channels, set_location_user \u001b[38;5;241m=\u001b[39m generate_channel(params_system,\n\u001b[0;32m      3\u001b[0m                                                num_samples\u001b[38;5;241m=\u001b[39mnum_sample, location_user_initial\u001b[38;5;241m=\u001b[39mlocation_user,\n\u001b[0;32m      4\u001b[0m                                                Rician_factor\u001b[38;5;241m=\u001b[39mRician_factor,num_RIS\u001b[38;5;241m=\u001b[39mnum_RIS)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[0;32m      7\u001b[0m G_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(channels[\u001b[38;5;241m1\u001b[39m])[:,:N_RIS\u001b[38;5;241m*\u001b[39mnum_RIS,:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params_system' is not defined"
     ]
    }
   ],
   "source": [
    "#generate channel and create dataset\n",
    "channels, set_location_user = generate_channel(params_system,\n",
    "                                               num_samples=num_sample, location_user_initial=location_user,\n",
    "                                               Rician_factor=Rician_factor,num_RIS=num_RIS)\n",
    "\n",
    "#%%\n",
    "G_train = torch.tensor(channels[1])[:,:N_RIS*num_RIS,:]\n",
    "H_train = torch.tensor(channels[2])[:,:,:N_RIS*num_RIS]\n",
    "\n",
    "\n",
    "H_train = H_train.type(torch.complex64)\n",
    "G_train = G_train.type(torch.complex64)\n",
    "\n",
    "\n",
    "#%%\n",
    "batch_size = 64\n",
    "val_data = PCDataset(H_train[train_num:], G_train[train_num:], Nt, N_RIS, num_RIS, K)\n",
    "val_loader = DataLoader(val_data, batch_size, shuffle=False, collate_fn=collate)\n",
    "#%%\n",
    "train_data = PCDataset(H_train[0:train_num], G_train[0:train_num], Nt, N_RIS, num_RIS, K)\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "763f37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available()==True else 'cpu')\n",
    "model = RGCN().to(device)\n",
    "#%%\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.9)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac72132",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c4c50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "val_rate = 0\n",
    "record = []\n",
    "for epoch in range(0, 50):\n",
    "    \n",
    "    # if epoch % 5 == 0:\n",
    "    train_rate = train(model,device)\n",
    "    val_rate, a,b,c = test(val_loader)\n",
    "    \n",
    "    print('Epoch {:03d}, Train Rate: {:.4f}, Val rate: {:.4f}'.format(\n",
    "        epoch, train_rate, val_rate))\n",
    "    record.append(train_rate)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ae4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "torch.save(model.state_dict(),'RIS_HetnetGNN_train16RIS_16x8MIMO_10000sample_ver4_test5pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e8323",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd033d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the trained model\n",
    "model.load_state_dict(torch.load('RIS_HetnetGNN_train16RIS_16x8MIMO_10000sample_ver4_test4.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4133be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield x\n",
    "        x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6a3ad2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 24 is out of bounds for dimension 2 with size 24",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m H_test \u001b[38;5;241m=\u001b[39m H_test\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[0;32m     28\u001b[0m G_test \u001b[38;5;241m=\u001b[39m G_test\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mcomplex64)\n\u001b[1;32m---> 30\u001b[0m test_data \u001b[38;5;241m=\u001b[39m PCDataset(H_test, G_test, Nt, N_RIS, num_RIS, K)\n\u001b[0;32m     31\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_data, test_sample, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate)\n\u001b[0;32m     32\u001b[0m test_rate, beam, phase, amplitude \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mPCDataset.__init__\u001b[1;34m(self, H, G, Nt, N_RIS, num_RIS, K)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_RIS \u001b[38;5;241m=\u001b[39m N_RIS\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_cg()\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeamforming\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\HaAn\\Lib\\site-packages\\dgl\\data\\dgl_dataset.py:112\u001b[0m, in \u001b[0;36mDGLDataset.__init__\u001b[1;34m(self, name, url, raw_dir, save_dir, hash_key, force_reload, verbose, transform)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_dir \u001b[38;5;241m=\u001b[39m save_dir\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\HaAn\\Lib\\site-packages\\dgl\\data\\dgl_dataset.py:203\u001b[0m, in \u001b[0;36mDGLDataset._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m load_flag:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "Cell \u001b[1;32mIn[9], line 84\u001b[0m, in \u001b[0;36mPCDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 84\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_graph(i)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_list\u001b[38;5;241m.\u001b[39mappend(graph)\n",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m, in \u001b[0;36mPCDataset.build_graph\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_RIS\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_RIS):\n\u001b[1;32m---> 34\u001b[0m         temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH[idx,:,i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG[idx,i,k]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     35\u001b[0m         temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(temp)\n\u001b[0;32m     36\u001b[0m         edge_ft_RIS_UE[count] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(temp,(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mNt,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mIndexError\u001b[0m: index 24 is out of bounds for dimension 2 with size 24"
     ]
    }
   ],
   "source": [
    "#system parameter\n",
    "Nt = 16 #Number of BS antenna\n",
    " \n",
    "K = 8 #number of user\n",
    "num_RIS = 4 #Number of RISs\n",
    "\n",
    "N_RIS_range = list(frange(4,17,2))#Number of RIS elements\n",
    "\n",
    "test_sample = 100\n",
    "Pmax = 1\n",
    "num_antenna_bs, N_RIS, K, num_sample = Nt, N_RIS, K, test_sample\n",
    "params_system = (num_antenna_bs, N_RIS, K)\n",
    "noise_power_db, Rician_factor = -100, 2\n",
    "location_user = None\n",
    "test_rate_array = []\n",
    "for n in range(0, len(N_RIS_range)):\n",
    "    N_RIS = N_RIS_range[n]\n",
    "    channels, set_location_user = generate_channel(params_system,\n",
    "                                                   num_samples=num_sample, location_user_initial=location_user,\n",
    "                                                   Rician_factor=Rician_factor,num_RIS=num_RIS)\n",
    "\n",
    "\n",
    "    G_test = torch.tensor(channels[1])[:,:N_RIS*num_RIS,:]\n",
    "    H_test= torch.tensor(channels[2])[:,:,:N_RIS*num_RIS]\n",
    "\n",
    "\n",
    "    H_test = H_test.type(torch.complex64)\n",
    "    G_test = G_test.type(torch.complex64)\n",
    "\n",
    "    test_data = PCDataset(H_test, G_test, Nt, N_RIS, num_RIS, K)\n",
    "    test_loader = DataLoader(test_data, test_sample, shuffle=False, collate_fn=collate)\n",
    "    test_rate, beam, phase, amplitude = test(test_loader)\n",
    "    \n",
    "    test_rate_array.append(-test_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the result\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_rate_array = \n",
    "Total_N_RIS = [x*num_RIS for x in N_RIS_range]\n",
    "plt.plot(Total_N_RIS, test_rate_array, 'bo',label='HetGNN')\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Total number of RIS elements')\n",
    "plt.ylabel('System Sum rate (bps/Hz)')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661875c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
